{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tic Tac Toe\n",
    "---\n",
    "Two players against each other\n",
    "\n",
    "<img style=\"float:left\" src=\"board.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARD_ROWS = 3\n",
    "BOARD_COLS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Board State\n",
    "---\n",
    "Reflect & Judge the state\n",
    "\n",
    "2 players p1 and p2; p1 uses symbol 1 and p2 uses symbol 2, vacancy as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, p1, p2):\n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS), dtype = np.int32)\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.isEnd = False\n",
    "        self.boardHash = None\n",
    "        # init p1 plays first\n",
    "        self.playerSymbol = 1\n",
    "    \n",
    "    # get unique hash of current board state\n",
    "    def getHash(self):\n",
    "        self.boardHash = str(self.board.reshape(BOARD_COLS*BOARD_ROWS))\n",
    "        return self.boardHash\n",
    "    \n",
    "    def winner(self):\n",
    "        # row\n",
    "        for i in range(BOARD_ROWS):\n",
    "            if sum(self.board[i, :]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            if sum(self.board[i, :]) == -3:\n",
    "                self.isEnd = True\n",
    "                return -1\n",
    "        # col\n",
    "        for i in range(BOARD_COLS):\n",
    "            if sum(self.board[:, i]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            if sum(self.board[:, i]) == -3:\n",
    "                self.isEnd = True\n",
    "                return -1\n",
    "        # diagonal\n",
    "        diag_sum1 = sum([self.board[i, i] for i in range(BOARD_COLS)])\n",
    "        diag_sum2 = sum([self.board[i, BOARD_COLS-i-1] for i in range(BOARD_COLS)])\n",
    "        diag_sum = max(diag_sum1, diag_sum2)\n",
    "        if diag_sum == 3:\n",
    "            self.isEnd = True\n",
    "            return 1\n",
    "        if diag_sum == -3:\n",
    "            self.isEnd = True\n",
    "            return -1\n",
    "        \n",
    "        # tie\n",
    "        # no available positions\n",
    "        if len(self.availablePositions()) == 0:\n",
    "            self.isEnd = True\n",
    "            return 0\n",
    "        # not end\n",
    "        self.isEnd = False\n",
    "        return None\n",
    "    \n",
    "    def availablePositions(self):\n",
    "        positions = []\n",
    "        for i in range(BOARD_ROWS):\n",
    "            for j in range(BOARD_COLS):\n",
    "                if self.board[i, j] == 0:\n",
    "                    positions.append((i, j))  # need to be tuple\n",
    "        return positions\n",
    "    \n",
    "    def updateState(self, position):\n",
    "        self.board[position] = self.playerSymbol\n",
    "        # switch to another player\n",
    "        self.playerSymbol = -1 if self.playerSymbol == 1 else 1\n",
    "    \n",
    "    # only when game ends\n",
    "    def giveReward(self):\n",
    "        result = self.winner()\n",
    "        # backpropagate reward\n",
    "        if result == 1:\n",
    "            self.p1.feedReward(1)\n",
    "            self.p2.feedReward(0)\n",
    "        elif result == -1:\n",
    "            self.p1.feedReward(0)\n",
    "            self.p2.feedReward(1)\n",
    "        else:\n",
    "            self.p1.feedReward(0.1)\n",
    "            self.p2.feedReward(0.5)\n",
    "    \n",
    "    # board reset\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((BOARD_ROWS, BOARD_COLS), dtype = np.int32)\n",
    "        self.boardHash = None\n",
    "        self.isEnd = False\n",
    "        self.playerSymbol = 1\n",
    "    \n",
    "    def play(self, rounds=100):\n",
    "        for i in range(rounds):\n",
    "            if i%1000 == 0:\n",
    "                print(\"Rounds {}\".format(i))\n",
    "            while not self.isEnd:\n",
    "                # Player 1\n",
    "                positions = self.availablePositions()\n",
    "                p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
    "                # take action and upate board state\n",
    "                self.updateState(p1_action)\n",
    "                board_hash = self.getHash()\n",
    "                self.p1.addState(board_hash)\n",
    "                # check board status if it is end\n",
    "\n",
    "                win = self.winner()\n",
    "                if win is not None:\n",
    "                    # self.showBoard()\n",
    "                    # ended with p1 either win or draw\n",
    "                    self.giveReward()\n",
    "                    self.p1.reset()\n",
    "                    self.p2.reset()\n",
    "                    self.reset()\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    # Player 2\n",
    "                    positions = self.availablePositions()\n",
    "                    p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol)\n",
    "                    self.updateState(p2_action)\n",
    "                    board_hash = self.getHash()\n",
    "                    self.p2.addState(board_hash)\n",
    "                    \n",
    "                    win = self.winner()\n",
    "                    if win is not None:\n",
    "                        # self.showBoard()\n",
    "                        # ended with p2 either win or draw\n",
    "                        self.giveReward()\n",
    "                        self.p1.reset()\n",
    "                        self.p2.reset()\n",
    "                        self.reset()\n",
    "                        break\n",
    "    \n",
    "    # play with human\n",
    "    def play2(self):\n",
    "        while not self.isEnd:\n",
    "            # Player 1\n",
    "            positions = self.availablePositions()\n",
    "            p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
    "            # take action and upate board state\n",
    "            self.updateState(p1_action)\n",
    "            self.showBoard()\n",
    "            # check board status if it is end\n",
    "            win = self.winner()\n",
    "            if win is not None:\n",
    "                if win == 1:\n",
    "                    print(self.p1.name, \"wins!\")\n",
    "                else:\n",
    "                    print(\"tie!\")\n",
    "                self.reset()\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                # Player 2\n",
    "                positions = self.availablePositions()\n",
    "                p2_action = self.p2.chooseAction(positions)\n",
    "\n",
    "                self.updateState(p2_action)\n",
    "                self.showBoard()\n",
    "                win = self.winner()\n",
    "                if win is not None:\n",
    "                    if win == -1:\n",
    "                        print(self.p2.name, \"wins!\")\n",
    "                    else:\n",
    "                        print(\"tie!\")\n",
    "                    self.reset()\n",
    "                    break\n",
    "\n",
    "    def showBoard(self):\n",
    "        # p1: x  p2: o\n",
    "        for i in range(0, BOARD_ROWS):\n",
    "            print('-------------')\n",
    "            out = '| '\n",
    "            for j in range(0, BOARD_COLS):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('-------------')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, name, exp_rate=0.3):\n",
    "        self.name = name\n",
    "        self.states = []  # record all positions taken\n",
    "        self.lr = 0.2\n",
    "        self.exp_rate = exp_rate\n",
    "        self.decay_gamma = 0.9\n",
    "        self.states_value = {}  # state -> value\n",
    "    \n",
    "    def getHash(self, board):\n",
    "        boardHash = str(board.reshape(BOARD_COLS*BOARD_ROWS))\n",
    "        return boardHash\n",
    "    \n",
    "    def chooseAction(self, positions, current_board, symbol):\n",
    "        if np.random.uniform(0, 1) <= self.exp_rate:\n",
    "            # take random action\n",
    "            idx = np.random.choice(len(positions))\n",
    "            action = positions[idx]\n",
    "        else:\n",
    "            value_max = -999\n",
    "            for p in positions:\n",
    "                next_board = current_board.copy()\n",
    "                next_board[p] = symbol\n",
    "                next_boardHash = self.getHash(next_board)\n",
    "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
    "                # print(\"value\", value)\n",
    "                if value >= value_max:\n",
    "                    value_max = value\n",
    "                    action = p\n",
    "        # print(\"{} takes action {}\".format(self.name, action))\n",
    "        return action\n",
    "    \n",
    "    # append a hash state\n",
    "    def addState(self, state):\n",
    "        self.states.append(state)\n",
    "    \n",
    "    # at the end of game, backpropagate and update states value\n",
    "    def feedReward(self, reward):\n",
    "        for st in reversed(self.states):\n",
    "            if self.states_value.get(st) is None:\n",
    "                self.states_value[st] = 0\n",
    "            self.states_value[st] += self.lr*(self.decay_gamma*reward - self.states_value[st])\n",
    "            reward = self.states_value[st]\n",
    "            \n",
    "    def reset(self):\n",
    "        self.states = []\n",
    "        \n",
    "    def savePolicy(self):\n",
    "        fw = open('policy_' + str(self.name), 'wb')\n",
    "        pickle.dump(self.states_value, fw)\n",
    "        fw.close()\n",
    "\n",
    "    def loadPolicy(self, file):\n",
    "        fr = open(file,'rb')\n",
    "        self.states_value = pickle.load(fr)\n",
    "        fr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanPlayer:\n",
    "    def __init__(self, name):\n",
    "        self.name = name \n",
    "    \n",
    "    def chooseAction(self, positions):\n",
    "        while True:\n",
    "            row = int(input(\"Input your action row:\"))\n",
    "            col = int(input(\"Input your action col:\"))\n",
    "            action = (row, col)\n",
    "            if action in positions:\n",
    "                return action\n",
    "    \n",
    "    # append a hash state\n",
    "    def addState(self, state):\n",
    "        pass\n",
    "    \n",
    "    # at the end of game, backpropagate and update states value\n",
    "    def feedReward(self, reward):\n",
    "        pass\n",
    "            \n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "Rounds 0\n",
      "Rounds 1000\n",
      "Rounds 2000\n",
      "Rounds 3000\n",
      "Rounds 4000\n",
      "Rounds 5000\n",
      "Rounds 6000\n",
      "Rounds 7000\n",
      "Rounds 8000\n",
      "Rounds 9000\n",
      "Rounds 10000\n",
      "Rounds 11000\n",
      "Rounds 12000\n",
      "Rounds 13000\n",
      "Rounds 14000\n",
      "Rounds 15000\n",
      "Rounds 16000\n",
      "Rounds 17000\n",
      "Rounds 18000\n",
      "Rounds 19000\n",
      "Rounds 20000\n",
      "Rounds 21000\n",
      "Rounds 22000\n",
      "Rounds 23000\n",
      "Rounds 24000\n",
      "Rounds 25000\n",
      "Rounds 26000\n",
      "Rounds 27000\n",
      "Rounds 28000\n",
      "Rounds 29000\n",
      "Rounds 30000\n",
      "Rounds 31000\n",
      "Rounds 32000\n",
      "Rounds 33000\n",
      "Rounds 34000\n",
      "Rounds 35000\n",
      "Rounds 36000\n",
      "Rounds 37000\n",
      "Rounds 38000\n",
      "Rounds 39000\n",
      "Rounds 40000\n",
      "Rounds 41000\n",
      "Rounds 42000\n",
      "Rounds 43000\n",
      "Rounds 44000\n",
      "Rounds 45000\n",
      "Rounds 46000\n",
      "Rounds 47000\n",
      "Rounds 48000\n",
      "Rounds 49000\n"
     ]
    }
   ],
   "source": [
    "p1 = Player(\"p1\")\n",
    "p2 = Player(\"p2\")\n",
    "\n",
    "st = State(p1, p2)\n",
    "print(\"training...\")\n",
    "st.play(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.savePolicy()\n",
    "p2.savePolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.loadPolicy(\"policy_p1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human vs Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "Input your action row:2\n",
      "Input your action col:2\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "|   | x | o | \n",
      "-------------\n",
      "Input your action row:0\n",
      "Input your action col:1\n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "|   | x | o | \n",
      "-------------\n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "|   | x | o | \n",
      "-------------\n",
      "Input your action row:1\n",
      "Input your action col:1\n",
      "Input your action row:1\n",
      "Input your action col:0\n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| o | x |   | \n",
      "-------------\n",
      "|   | x | o | \n",
      "-------------\n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| o | x |   | \n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n",
      "computer wins!\n"
     ]
    }
   ],
   "source": [
    "p1 = Player(\"computer\", exp_rate=0)\n",
    "p1.loadPolicy(\"policy_p1\")\n",
    "\n",
    "p2 = HumanPlayer(\"human\")\n",
    "\n",
    "st = State(p1, p2)\n",
    "st.play2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "Input your action row:2\n",
      "Input your action col:2\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | x | x | \n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "Input your action row:1\n",
      "Input your action col:0\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "| o | x | x | \n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "| o | x | x | \n",
      "-------------\n",
      "| x |   | o | \n",
      "-------------\n",
      "Input your action row:0\n",
      "Input your action col:0\n",
      "-------------\n",
      "| o |   |   | \n",
      "-------------\n",
      "| o | x | x | \n",
      "-------------\n",
      "| x |   | o | \n",
      "-------------\n",
      "-------------\n",
      "| o |   | x | \n",
      "-------------\n",
      "| o | x | x | \n",
      "-------------\n",
      "| x |   | o | \n",
      "-------------\n",
      "computer wins!\n"
     ]
    }
   ],
   "source": [
    "p1 = Player(\"computer\", exp_rate=0)\n",
    "p1.loadPolicy(\"policy_p1\")\n",
    "\n",
    "p2 = HumanPlayer(\"human\")\n",
    "\n",
    "st = State(p1, p2)\n",
    "st.play2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
